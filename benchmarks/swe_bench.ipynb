{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/douglasschonholtz/aim/SWE-Bench-Runner/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dev split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 22360.88 examples/s]\n",
      "Generating test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2294/2294 [00:00<00:00, 64760.11 examples/s]\n",
      "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19008/19008 [00:00<00:00, 72707.26 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"princeton-nlp/SWE-bench\", \"default\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_dataset(\"princeton-nlp/SWE-bench\", \"default\", split=\"test\")\n",
    "# convert the dataset to a dataframe\n",
    "test_df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>base_commit</th>\n",
       "      <th>hints_text</th>\n",
       "      <th>repo</th>\n",
       "      <th>problem_statement</th>\n",
       "      <th>patch</th>\n",
       "      <th>test_patch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-04T10:05:33Z</td>\n",
       "      <td>3832210580d516365ddae1a62071001faf94d416</td>\n",
       "      <td>Welcome to Astropy ðŸ‘‹ and thank you for your fi...</td>\n",
       "      <td>astropy/astropy</td>\n",
       "      <td>'WCS.all_world2pix' failed to converge when pl...</td>\n",
       "      <td>diff --git a/astropy/wcs/wcsapi/fitswcs.py b/a...</td>\n",
       "      <td>diff --git a/astropy/wcs/wcsapi/tests/test_fit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-08-14T10:06:53Z</td>\n",
       "      <td>b6769c18c0881b6d290e543e9334c25043018b3f</td>\n",
       "      <td>See also #10128 which is maybe not exactly the...</td>\n",
       "      <td>astropy/astropy</td>\n",
       "      <td>Add helpers to convert between different types...</td>\n",
       "      <td>diff --git a/astropy/nddata/nduncertainty.py b...</td>\n",
       "      <td>diff --git a/astropy/nddata/tests/test_nduncer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-28T15:32:17Z</td>\n",
       "      <td>43ce7895bb5b61d4fab2f9cc7d07016cf105f18e</td>\n",
       "      <td>I forgot who added that part of `BlackBody`. I...</td>\n",
       "      <td>astropy/astropy</td>\n",
       "      <td>BlackBody bolometric flux is wrong if scale ha...</td>\n",
       "      <td>diff --git a/astropy/modeling/physical_models....</td>\n",
       "      <td>diff --git a/astropy/modeling/tests/test_physi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-30T16:14:01Z</td>\n",
       "      <td>3a0cd2d8cd7b459cdc1e1b97a14f3040ccc1fffc</td>\n",
       "      <td></td>\n",
       "      <td>astropy/astropy</td>\n",
       "      <td>Can Table masking be turned off?\\n&lt;!-- This co...</td>\n",
       "      <td>diff --git a/astropy/io/fits/connect.py b/astr...</td>\n",
       "      <td>diff --git a/astropy/io/fits/tests/test_connec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-05T12:13:44Z</td>\n",
       "      <td>43ee5806e9c6f7d58c12c1cb9287b3c61abe489d</td>\n",
       "      <td>Hmm. Maybe the logic here needs fixing:\\r\\n\\r\\...</td>\n",
       "      <td>astropy/astropy</td>\n",
       "      <td>SkyCoord in Table breaks aggregate on group_by...</td>\n",
       "      <td>diff --git a/astropy/table/column.py b/astropy...</td>\n",
       "      <td>diff --git a/astropy/table/tests/conftest.py b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             created_at                               base_commit  \\\n",
       "0  2021-05-04T10:05:33Z  3832210580d516365ddae1a62071001faf94d416   \n",
       "1  2021-08-14T10:06:53Z  b6769c18c0881b6d290e543e9334c25043018b3f   \n",
       "2  2021-10-28T15:32:17Z  43ce7895bb5b61d4fab2f9cc7d07016cf105f18e   \n",
       "3  2021-11-30T16:14:01Z  3a0cd2d8cd7b459cdc1e1b97a14f3040ccc1fffc   \n",
       "4  2022-02-05T12:13:44Z  43ee5806e9c6f7d58c12c1cb9287b3c61abe489d   \n",
       "\n",
       "                                          hints_text             repo  \\\n",
       "0  Welcome to Astropy ðŸ‘‹ and thank you for your fi...  astropy/astropy   \n",
       "1  See also #10128 which is maybe not exactly the...  astropy/astropy   \n",
       "2  I forgot who added that part of `BlackBody`. I...  astropy/astropy   \n",
       "3                                                     astropy/astropy   \n",
       "4  Hmm. Maybe the logic here needs fixing:\\r\\n\\r\\...  astropy/astropy   \n",
       "\n",
       "                                   problem_statement  \\\n",
       "0  'WCS.all_world2pix' failed to converge when pl...   \n",
       "1  Add helpers to convert between different types...   \n",
       "2  BlackBody bolometric flux is wrong if scale ha...   \n",
       "3  Can Table masking be turned off?\\n<!-- This co...   \n",
       "4  SkyCoord in Table breaks aggregate on group_by...   \n",
       "\n",
       "                                               patch  \\\n",
       "0  diff --git a/astropy/wcs/wcsapi/fitswcs.py b/a...   \n",
       "1  diff --git a/astropy/nddata/nduncertainty.py b...   \n",
       "2  diff --git a/astropy/modeling/physical_models....   \n",
       "3  diff --git a/astropy/io/fits/connect.py b/astr...   \n",
       "4  diff --git a/astropy/table/column.py b/astropy...   \n",
       "\n",
       "                                          test_patch  \n",
       "0  diff --git a/astropy/wcs/wcsapi/tests/test_fit...  \n",
       "1  diff --git a/astropy/nddata/tests/test_nduncer...  \n",
       "2  diff --git a/astropy/modeling/tests/test_physi...  \n",
       "3  diff --git a/astropy/io/fits/tests/test_connec...  \n",
       "4  diff --git a/astropy/table/tests/conftest.py b...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_data_path = Path.cwd() / \"data\" / \"test-00000-of-00001-7e897d4aeb3d3eab.parquet\"\n",
    "# train_data_path = Path.cwd() / \"data\" / \"train-00000-of-00001-de6a857746501057.parquet\"\n",
    "# train_df = pd.read_parquet(train_data_path)\n",
    "# test_df = pd.read_parquet(test_data_path)\n",
    "# filter test_df down to created_at, repo, problem_statement, and patch\n",
    "test_df = test_df[['created_at', 'base_commit', 'hints_text', 'repo', 'problem_statement', 'patch', 'test_patch']]\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort these by fail to pass and pass to fail\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>base_commit</th>\n",
       "      <th>hints_text</th>\n",
       "      <th>repo</th>\n",
       "      <th>problem_statement</th>\n",
       "      <th>patch</th>\n",
       "      <th>test_patch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-04T10:05:33Z</td>\n",
       "      <td>3832210580d516365ddae1a62071001faf94d416</td>\n",
       "      <td>Welcome to Astropy ðŸ‘‹ and thank you for your fi...</td>\n",
       "      <td>astropy/astropy</td>\n",
       "      <td>'WCS.all_world2pix' failed to converge when pl...</td>\n",
       "      <td>diff --git a/astropy/wcs/wcsapi/fitswcs.py b/a...</td>\n",
       "      <td>diff --git a/astropy/wcs/wcsapi/tests/test_fit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-08-14T10:06:53Z</td>\n",
       "      <td>b6769c18c0881b6d290e543e9334c25043018b3f</td>\n",
       "      <td>See also #10128 which is maybe not exactly the...</td>\n",
       "      <td>astropy/astropy</td>\n",
       "      <td>Add helpers to convert between different types...</td>\n",
       "      <td>diff --git a/astropy/nddata/nduncertainty.py b...</td>\n",
       "      <td>diff --git a/astropy/nddata/tests/test_nduncer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-28T15:32:17Z</td>\n",
       "      <td>43ce7895bb5b61d4fab2f9cc7d07016cf105f18e</td>\n",
       "      <td>I forgot who added that part of `BlackBody`. I...</td>\n",
       "      <td>astropy/astropy</td>\n",
       "      <td>BlackBody bolometric flux is wrong if scale ha...</td>\n",
       "      <td>diff --git a/astropy/modeling/physical_models....</td>\n",
       "      <td>diff --git a/astropy/modeling/tests/test_physi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-30T16:14:01Z</td>\n",
       "      <td>3a0cd2d8cd7b459cdc1e1b97a14f3040ccc1fffc</td>\n",
       "      <td></td>\n",
       "      <td>astropy/astropy</td>\n",
       "      <td>Can Table masking be turned off?\\n&lt;!-- This co...</td>\n",
       "      <td>diff --git a/astropy/io/fits/connect.py b/astr...</td>\n",
       "      <td>diff --git a/astropy/io/fits/tests/test_connec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-05T12:13:44Z</td>\n",
       "      <td>43ee5806e9c6f7d58c12c1cb9287b3c61abe489d</td>\n",
       "      <td>Hmm. Maybe the logic here needs fixing:\\r\\n\\r\\...</td>\n",
       "      <td>astropy/astropy</td>\n",
       "      <td>SkyCoord in Table breaks aggregate on group_by...</td>\n",
       "      <td>diff --git a/astropy/table/column.py b/astropy...</td>\n",
       "      <td>diff --git a/astropy/table/tests/conftest.py b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             created_at                               base_commit  \\\n",
       "0  2021-05-04T10:05:33Z  3832210580d516365ddae1a62071001faf94d416   \n",
       "1  2021-08-14T10:06:53Z  b6769c18c0881b6d290e543e9334c25043018b3f   \n",
       "2  2021-10-28T15:32:17Z  43ce7895bb5b61d4fab2f9cc7d07016cf105f18e   \n",
       "3  2021-11-30T16:14:01Z  3a0cd2d8cd7b459cdc1e1b97a14f3040ccc1fffc   \n",
       "4  2022-02-05T12:13:44Z  43ee5806e9c6f7d58c12c1cb9287b3c61abe489d   \n",
       "\n",
       "                                          hints_text             repo  \\\n",
       "0  Welcome to Astropy ðŸ‘‹ and thank you for your fi...  astropy/astropy   \n",
       "1  See also #10128 which is maybe not exactly the...  astropy/astropy   \n",
       "2  I forgot who added that part of `BlackBody`. I...  astropy/astropy   \n",
       "3                                                     astropy/astropy   \n",
       "4  Hmm. Maybe the logic here needs fixing:\\r\\n\\r\\...  astropy/astropy   \n",
       "\n",
       "                                   problem_statement  \\\n",
       "0  'WCS.all_world2pix' failed to converge when pl...   \n",
       "1  Add helpers to convert between different types...   \n",
       "2  BlackBody bolometric flux is wrong if scale ha...   \n",
       "3  Can Table masking be turned off?\\n<!-- This co...   \n",
       "4  SkyCoord in Table breaks aggregate on group_by...   \n",
       "\n",
       "                                               patch  \\\n",
       "0  diff --git a/astropy/wcs/wcsapi/fitswcs.py b/a...   \n",
       "1  diff --git a/astropy/nddata/nduncertainty.py b...   \n",
       "2  diff --git a/astropy/modeling/physical_models....   \n",
       "3  diff --git a/astropy/io/fits/connect.py b/astr...   \n",
       "4  diff --git a/astropy/table/column.py b/astropy...   \n",
       "\n",
       "                                          test_patch  \n",
       "0  diff --git a/astropy/wcs/wcsapi/tests/test_fit...  \n",
       "1  diff --git a/astropy/nddata/tests/test_nduncer...  \n",
       "2  diff --git a/astropy/modeling/tests/test_physi...  \n",
       "3  diff --git a/astropy/io/fits/tests/test_connec...  \n",
       "4  diff --git a/astropy/table/tests/conftest.py b...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Astropy ðŸ‘‹ and thank you for your first issue!\n",
      "\n",
      "A project member will respond to you as soon as possible; in the meantime, please double-check the [guidelines for submitting issues](https://github.com/astropy/astropy/blob/master/CONTRIBUTING.md#reporting-issues) and make sure you've provided the requested details.\n",
      "\n",
      "If you feel that this issue has not been responded to in a timely manner, please leave a comment mentioning our software support engineer @embray, or send a message directly to the [development mailing list](http://groups.google.com/group/astropy-dev).  If the issue is urgent or sensitive in nature (e.g., a security vulnerability) please send an e-mail directly to the private e-mail feedback@astropy.org.\n",
      "You could also directly call\n",
      "\n",
      "```python\n",
      "pixel = self.all_world2pix(*world_arrays, 0)\n",
      "pixel = pixel[0] if self.pixel_n_dim == 1 else tuple(pixel)\n",
      "```\n",
      "\n",
      "without patching any code.  But I wonder if the WCSAPI methods shouldn't allow passing additional keyword args to the underlying WCS methods (like `all_world2pix` in this case).  @astrofrog is the one who first introduces this API I think.\n",
      "I think the cleanest fix here would be that really the FITS WCS APE14 wrapper should call all_* in a way that only emits a warning not raises an exception (since by design we can't pass kwargs through). It's then easy for users to ignore the warning if they really want.\n",
      "\n",
      "@Cadair any thoughts?\n",
      "\n",
      "Is this technically a bug?\n",
      "> the FITS WCS APE14 wrapper should call all_* in a way that only emits a warning\n",
      "\n",
      "This is probably the best solution. I certainly can't think of a better one.\n",
      "\n",
      "On keyword arguments to WCSAPI, if we did allow that we would have to mandate that all implementations allowed `**kwargs` to accept and ignore all unknown kwargs so that you didn't make it implementation specific when calling the method, which is a big ugly.\n",
      "> Is this technically a bug?\n",
      "\n",
      "I would say so yes.\n",
      "> > the FITS WCS APE14 wrapper should call all_* in a way that only emits a warning\n",
      "> \n",
      "> This is probably the best solution. I certainly can't think of a better one.\n",
      "> \n",
      "\n",
      "That solution would be also fine for me.\n",
      "\n",
      "\n",
      "@karlwessel , are you interested in submitting a patch for this? ðŸ˜¸ \n",
      "In principle yes, but at the moment I really can't say.\n",
      "\n",
      "Which places would this affect? Only all calls to `all_*` in `wcsapi/fitswcs.py`?\n",
      "Yes I think that's right\n",
      "For what it is worth, my comment is about the issues with the example. I think so far the history of `all_pix2world` shows that it is a very stable algorithm that converges for all \"real\" astronomical images. So, I wanted to learn about this failure. [NOTE: This does not mean that you should not catch exceptions in `pixel_to_world()` if you wish so.]\n",
      "\n",
      "There are several issues with the example:\n",
      "1. Because `CTYPE` is not set, essentially the projection algorithm is linear, that is, intermediate physical coordinates are the world coordinates.\n",
      "2. SIP standard assumes that polynomials share the same CRPIX with the WCS. Here, CRPIX of the `Wcsprm` is `[0, 0]` while the CRPIX of the SIP is set to `[1221.87375165,  994.90917378]`\n",
      "3. If you run `wcs.all_pix2world(1, 1, 1)` you will get `[421.5126801, 374.13077558]` for world coordinates (and at CRPIX you will get CRVAL which is 0). This is in degrees. You can see that from the center pixel (CRPIX) to the corner of the image you are circling the celestial sphere many times (well, at least once; I did not check the other corners).\n",
      "\n",
      "In summary, yes `all_world2pix` can fail but it does not imply that there is a bug in it. This example simply contains large distortions (like mapping `(1, 1) -> [421, 374]`) that cannot be handled with the currently implemented algorithm but I am not sure there is another algorithm that could do better.\n",
      "\n",
      "With regard to throwing or not an exception... that's tough. On one hand, for those who are interested in correctness of the values, it is better to know that the algorithm failed and one cannot trust returned values. For plotting, this may be an issue and one would prefer to just get, maybe, the linear approximation. My personal preference is for exceptions because they can be caught and dealt with by the caller.\n",
      "The example is a minimal version of our real WCS whichs nonlinear distortion is taken from a checkerboard image and it fits it quit well:\n",
      "![fitteddistortion](https://user-images.githubusercontent.com/64231/116892995-be892a00-ac30-11eb-826f-99e3635af1fa.png)\n",
      "\n",
      "The WCS was fitted with `fit_wcs_from_points` using an artificial very small 'RA/DEC-TAN' grid so that it is almost linear.\n",
      "\n",
      "I guess the Problem is that the camera really has a huge distortion which just isn't fitable with a polynomial. Nevertheless it still is a real camera distortion, but I agree in that it probably is not worth to be considered a bug in the `all_world2pix` method.\n",
      "Welcome to Astropy ðŸ‘‹ and thank you for your first issue!\n",
      "\n",
      "A project member will respond to you as soon as possible; in the meantime, please double-check the [guidelines for submitting issues](https://github.com/astropy/astropy/blob/master/CONTRIBUTING.md#reporting-issues) and make sure you've provided the requested details.\n",
      "\n",
      "If you feel that this issue has not been responded to in a timely manner, please leave a comment mentioning our software support engineer @embray, or send a message directly to the [development mailing list](http://groups.google.com/group/astropy-dev).  If the issue is urgent or sensitive in nature (e.g., a security vulnerability) please send an e-mail directly to the private e-mail feedback@astropy.org.\n",
      "You could also directly call\n",
      "\n",
      "```python\n",
      "pixel = self.all_world2pix(*world_arrays, 0)\n",
      "pixel = pixel[0] if self.pixel_n_dim == 1 else tuple(pixel)\n",
      "```\n",
      "\n",
      "without patching any code.  But I wonder if the WCSAPI methods shouldn't allow passing additional keyword args to the underlying WCS methods (like `all_world2pix` in this case).  @astrofrog is the one who first introduces this API I think.\n",
      "I think the cleanest fix here would be that really the FITS WCS APE14 wrapper should call all_* in a way that only emits a warning not raises an exception (since by design we can't pass kwargs through). It's then easy for users to ignore the warning if they really want.\n",
      "\n",
      "@Cadair any thoughts?\n",
      "\n",
      "Is this technically a bug?\n",
      "> the FITS WCS APE14 wrapper should call all_* in a way that only emits a warning\n",
      "\n",
      "This is probably the best solution. I certainly can't think of a better one.\n",
      "\n",
      "On keyword arguments to WCSAPI, if we did allow that we would have to mandate that all implementations allowed `**kwargs` to accept and ignore all unknown kwargs so that you didn't make it implementation specific when calling the method, which is a big ugly.\n",
      "> Is this technically a bug?\n",
      "\n",
      "I would say so yes.\n",
      "> > the FITS WCS APE14 wrapper should call all_* in a way that only emits a warning\n",
      "> \n",
      "> This is probably the best solution. I certainly can't think of a better one.\n",
      "> \n",
      "\n",
      "That solution would be also fine for me.\n",
      "\n",
      "\n",
      "@karlwessel , are you interested in submitting a patch for this? ðŸ˜¸ \n",
      "In principle yes, but at the moment I really can't say.\n",
      "\n",
      "Which places would this affect? Only all calls to `all_*` in `wcsapi/fitswcs.py`?\n",
      "Yes I think that's right\n",
      "For what it is worth, my comment is about the issues with the example. I think so far the history of `all_pix2world` shows that it is a very stable algorithm that converges for all \"real\" astronomical images. So, I wanted to learn about this failure. [NOTE: This does not mean that you should not catch exceptions in `pixel_to_world()` if you wish so.]\n",
      "\n",
      "There are several issues with the example:\n",
      "1. Because `CTYPE` is not set, essentially the projection algorithm is linear, that is, intermediate physical coordinates are the world coordinates.\n",
      "2. SIP standard assumes that polynomials share the same CRPIX with the WCS. Here, CRPIX of the `Wcsprm` is `[0, 0]` while the CRPIX of the SIP is set to `[1221.87375165,  994.90917378]`\n",
      "3. If you run `wcs.all_pix2world(1, 1, 1)` you will get `[421.5126801, 374.13077558]` for world coordinates (and at CRPIX you will get CRVAL which is 0). This is in degrees. You can see that from the center pixel (CRPIX) to the corner of the image you are circling the celestial sphere many times (well, at least once; I did not check the other corners).\n",
      "\n",
      "In summary, yes `all_world2pix` can fail but it does not imply that there is a bug in it. This example simply contains large distortions (like mapping `(1, 1) -> [421, 374]`) that cannot be handled with the currently implemented algorithm but I am not sure there is another algorithm that could do better.\n",
      "\n",
      "With regard to throwing or not an exception... that's tough. On one hand, for those who are interested in correctness of the values, it is better to know that the algorithm failed and one cannot trust returned values. For plotting, this may be an issue and one would prefer to just get, maybe, the linear approximation. My personal preference is for exceptions because they can be caught and dealt with by the caller.\n",
      "The example is a minimal version of our real WCS whichs nonlinear distortion is taken from a checkerboard image and it fits it quit well:\n",
      "![fitteddistortion](https://user-images.githubusercontent.com/64231/116892995-be892a00-ac30-11eb-826f-99e3635af1fa.png)\n",
      "\n",
      "The WCS was fitted with `fit_wcs_from_points` using an artificial very small 'RA/DEC-TAN' grid so that it is almost linear.\n",
      "\n",
      "I guess the Problem is that the camera really has a huge distortion which just isn't fitable with a polynomial. Nevertheless it still is a real camera distortion, but I agree in that it probably is not worth to be considered a bug in the `all_world2pix` method.\n"
     ]
    }
   ],
   "source": [
    "print(test_df[\"hints_text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patches = train_df[\"patch\"].loc[1:3]\n",
    "# print(patches[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test parquet as json\n",
    "test_df.to_json(\"test.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at           2294\n",
       "base_commit          2294\n",
       "hints_text           2294\n",
       "repo                 2294\n",
       "problem_statement    2294\n",
       "patch                2294\n",
       "test_patch           2294\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all of the rows with nan values and then show them\n",
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Astropy ðŸ‘‹ and thank you for your first issue!\n",
      "\n",
      "A project member will respond to you as soon as possible; in the meantime, please double-check the [guidelines for submitting issues](https://github.com/astropy/astropy/blob/master/CONTRIBUTING.md#reporting-issues) and make sure you've provided the requested details.\n",
      "\n",
      "If you feel that this issue has not been responded to in a timely manner, please leave a comment mentioning our software support engineer @embray, or send a message directly to the [development mailing list](http://groups.google.com/group/astropy-dev).  If the issue is urgent or sensitive in nature (e.g., a security vulnerability) please send an e-mail directly to the private e-mail feedback@astropy.org.\n",
      "You could also directly call\n",
      "\n",
      "```python\n",
      "pixel = self.all_world2pix(*world_arrays, 0)\n",
      "pixel = pixel[0] if self.pixel_n_dim == 1 else tuple(pixel)\n",
      "```\n",
      "\n",
      "without patching any code.  But I wonder if the WCSAPI methods shouldn't allow passing additional keyword args to the underlying WCS methods (like `all_world2pix` in this case).  @astrofrog is the one who first introduces this API I think.\n",
      "I think the cleanest fix here would be that really the FITS WCS APE14 wrapper should call all_* in a way that only emits a warning not raises an exception (since by design we can't pass kwargs through). It's then easy for users to ignore the warning if they really want.\n",
      "\n",
      "@Cadair any thoughts?\n",
      "\n",
      "Is this technically a bug?\n",
      "> the FITS WCS APE14 wrapper should call all_* in a way that only emits a warning\n",
      "\n",
      "This is probably the best solution. I certainly can't think of a better one.\n",
      "\n",
      "On keyword arguments to WCSAPI, if we did allow that we would have to mandate that all implementations allowed `**kwargs` to accept and ignore all unknown kwargs so that you didn't make it implementation specific when calling the method, which is a big ugly.\n",
      "> Is this technically a bug?\n",
      "\n",
      "I would say so yes.\n",
      "> > the FITS WCS APE14 wrapper should call all_* in a way that only emits a warning\n",
      "> \n",
      "> This is probably the best solution. I certainly can't think of a better one.\n",
      "> \n",
      "\n",
      "That solution would be also fine for me.\n",
      "\n",
      "\n",
      "@karlwessel , are you interested in submitting a patch for this? ðŸ˜¸ \n",
      "In principle yes, but at the moment I really can't say.\n",
      "\n",
      "Which places would this affect? Only all calls to `all_*` in `wcsapi/fitswcs.py`?\n",
      "Yes I think that's right\n",
      "For what it is worth, my comment is about the issues with the example. I think so far the history of `all_pix2world` shows that it is a very stable algorithm that converges for all \"real\" astronomical images. So, I wanted to learn about this failure. [NOTE: This does not mean that you should not catch exceptions in `pixel_to_world()` if you wish so.]\n",
      "\n",
      "There are several issues with the example:\n",
      "1. Because `CTYPE` is not set, essentially the projection algorithm is linear, that is, intermediate physical coordinates are the world coordinates.\n",
      "2. SIP standard assumes that polynomials share the same CRPIX with the WCS. Here, CRPIX of the `Wcsprm` is `[0, 0]` while the CRPIX of the SIP is set to `[1221.87375165,  994.90917378]`\n",
      "3. If you run `wcs.all_pix2world(1, 1, 1)` you will get `[421.5126801, 374.13077558]` for world coordinates (and at CRPIX you will get CRVAL which is 0). This is in degrees. You can see that from the center pixel (CRPIX) to the corner of the image you are circling the celestial sphere many times (well, at least once; I did not check the other corners).\n",
      "\n",
      "In summary, yes `all_world2pix` can fail but it does not imply that there is a bug in it. This example simply contains large distortions (like mapping `(1, 1) -> [421, 374]`) that cannot be handled with the currently implemented algorithm but I am not sure there is another algorithm that could do better.\n",
      "\n",
      "With regard to throwing or not an exception... that's tough. On one hand, for those who are interested in correctness of the values, it is better to know that the algorithm failed and one cannot trust returned values. For plotting, this may be an issue and one would prefer to just get, maybe, the linear approximation. My personal preference is for exceptions because they can be caught and dealt with by the caller.\n",
      "The example is a minimal version of our real WCS whichs nonlinear distortion is taken from a checkerboard image and it fits it quit well:\n",
      "![fitteddistortion](https://user-images.githubusercontent.com/64231/116892995-be892a00-ac30-11eb-826f-99e3635af1fa.png)\n",
      "\n",
      "The WCS was fitted with `fit_wcs_from_points` using an artificial very small 'RA/DEC-TAN' grid so that it is almost linear.\n",
      "\n",
      "I guess the Problem is that the camera really has a huge distortion which just isn't fitable with a polynomial. Nevertheless it still is a real camera distortion, but I agree in that it probably is not worth to be considered a bug in the `all_world2pix` method.\n",
      "Welcome to Astropy ðŸ‘‹ and thank you for your first issue!\n",
      "\n",
      "A project member will respond to you as soon as possible; in the meantime, please double-check the [guidelines for submitting issues](https://github.com/astropy/astropy/blob/master/CONTRIBUTING.md#reporting-issues) and make sure you've provided the requested details.\n",
      "\n",
      "If you feel that this issue has not been responded to in a timely manner, please leave a comment mentioning our software support engineer @embray, or send a message directly to the [development mailing list](http://groups.google.com/group/astropy-dev).  If the issue is urgent or sensitive in nature (e.g., a security vulnerability) please send an e-mail directly to the private e-mail feedback@astropy.org.\n",
      "You could also directly call\n",
      "\n",
      "```python\n",
      "pixel = self.all_world2pix(*world_arrays, 0)\n",
      "pixel = pixel[0] if self.pixel_n_dim == 1 else tuple(pixel)\n",
      "```\n",
      "\n",
      "without patching any code.  But I wonder if the WCSAPI methods shouldn't allow passing additional keyword args to the underlying WCS methods (like `all_world2pix` in this case).  @astrofrog is the one who first introduces this API I think.\n",
      "I think the cleanest fix here would be that really the FITS WCS APE14 wrapper should call all_* in a way that only emits a warning not raises an exception (since by design we can't pass kwargs through). It's then easy for users to ignore the warning if they really want.\n",
      "\n",
      "@Cadair any thoughts?\n",
      "\n",
      "Is this technically a bug?\n",
      "> the FITS WCS APE14 wrapper should call all_* in a way that only emits a warning\n",
      "\n",
      "This is probably the best solution. I certainly can't think of a better one.\n",
      "\n",
      "On keyword arguments to WCSAPI, if we did allow that we would have to mandate that all implementations allowed `**kwargs` to accept and ignore all unknown kwargs so that you didn't make it implementation specific when calling the method, which is a big ugly.\n",
      "> Is this technically a bug?\n",
      "\n",
      "I would say so yes.\n",
      "> > the FITS WCS APE14 wrapper should call all_* in a way that only emits a warning\n",
      "> \n",
      "> This is probably the best solution. I certainly can't think of a better one.\n",
      "> \n",
      "\n",
      "That solution would be also fine for me.\n",
      "\n",
      "\n",
      "@karlwessel , are you interested in submitting a patch for this? ðŸ˜¸ \n",
      "In principle yes, but at the moment I really can't say.\n",
      "\n",
      "Which places would this affect? Only all calls to `all_*` in `wcsapi/fitswcs.py`?\n",
      "Yes I think that's right\n",
      "For what it is worth, my comment is about the issues with the example. I think so far the history of `all_pix2world` shows that it is a very stable algorithm that converges for all \"real\" astronomical images. So, I wanted to learn about this failure. [NOTE: This does not mean that you should not catch exceptions in `pixel_to_world()` if you wish so.]\n",
      "\n",
      "There are several issues with the example:\n",
      "1. Because `CTYPE` is not set, essentially the projection algorithm is linear, that is, intermediate physical coordinates are the world coordinates.\n",
      "2. SIP standard assumes that polynomials share the same CRPIX with the WCS. Here, CRPIX of the `Wcsprm` is `[0, 0]` while the CRPIX of the SIP is set to `[1221.87375165,  994.90917378]`\n",
      "3. If you run `wcs.all_pix2world(1, 1, 1)` you will get `[421.5126801, 374.13077558]` for world coordinates (and at CRPIX you will get CRVAL which is 0). This is in degrees. You can see that from the center pixel (CRPIX) to the corner of the image you are circling the celestial sphere many times (well, at least once; I did not check the other corners).\n",
      "\n",
      "In summary, yes `all_world2pix` can fail but it does not imply that there is a bug in it. This example simply contains large distortions (like mapping `(1, 1) -> [421, 374]`) that cannot be handled with the currently implemented algorithm but I am not sure there is another algorithm that could do better.\n",
      "\n",
      "With regard to throwing or not an exception... that's tough. On one hand, for those who are interested in correctness of the values, it is better to know that the algorithm failed and one cannot trust returned values. For plotting, this may be an issue and one would prefer to just get, maybe, the linear approximation. My personal preference is for exceptions because they can be caught and dealt with by the caller.\n",
      "The example is a minimal version of our real WCS whichs nonlinear distortion is taken from a checkerboard image and it fits it quit well:\n",
      "![fitteddistortion](https://user-images.githubusercontent.com/64231/116892995-be892a00-ac30-11eb-826f-99e3635af1fa.png)\n",
      "\n",
      "The WCS was fitted with `fit_wcs_from_points` using an artificial very small 'RA/DEC-TAN' grid so that it is almost linear.\n",
      "\n",
      "I guess the Problem is that the camera really has a huge distortion which just isn't fitable with a polynomial. Nevertheless it still is a real camera distortion, but I agree in that it probably is not worth to be considered a bug in the `all_world2pix` method.\n",
      "\n",
      "\n",
      "\n",
      "END OF HINT\n",
      "\n",
      "\n",
      "\n",
      "See also #10128 which is maybe not exactly the same need but related in the sense that there is currently no easy way to get uncertainties in a specific format (variance, std).\n",
      "Very much from the left field, but in coordinate representations, we deal with this by insisting every representation can be transformed to/from cartesian, and then have a `represent_as` method that by default goes through cartesian. A similar scheme (probably going through variance) might well be possible here.\n",
      "It sounds like the `represent_as` method via variance would be reasonable, I'll see if I can spend some time coding something up (but if someone else wants to have a go, don't let me stop you).\n",
      "\n",
      "\n",
      "\n",
      "END OF HINT\n",
      "\n",
      "\n",
      "\n",
      "I forgot who added that part of `BlackBody`. It was either @karllark or @astrofrog .\n",
      "There are several problems here:\n",
      "\n",
      "1. In `BlackBody.evaluate()`, there is an `if` statement that handles two special cases: either scale is dimensionless, and multiplies the original blackbody surface brightness, or `scale` has units that are compatible with surface brightness, and replaces the original surface brightness. This check is broken, because it does not correctly handle the case that `scale` has a unit, but that unit is compatible with `dimensionless_unscaled`. This is easy to fix.\n",
      "2. The `BlackBody.bolometric_flux` method does not handle this special case. Again, this is easy to fix.\n",
      "3. In the case that  `scale` has units that are compatible with surface brightness, it is impossible to unambiguously determine the correct multiplier in `BlackBody.bolometric_flux`, because the conversion may depend on the frequency or wavelength at which the scale was given. This might be a design flaw.\n",
      "\n",
      "Unless I'm missing something, there is no way for this class to give an unambiguous and correct value of the bolometric flux, unless `scale` is dimensionless. Is that correct?\n",
      "Here's another weird output from BlackBody. I _think_ it's a manifestation of the same bug, or at least it's related. I create three black bodies:\n",
      "\n",
      "* `bb1` with a scale=1 erg / (cm2 Hz s sr)\n",
      "* `bb2` with a scale=1 J / (cm2 Hz s sr)\n",
      "* `bb3` with a scale=1e7 erg / (cm2 Hz s sr)\n",
      "\n",
      "The spectra from `bb1` and `bb2` look the same, even though `bb2` should be (1 J / 1 erg) = 1e7 times as bright! And the spectrum from `bb3` looks different from `bb2`, even though 1e7 erg = 1 J.\n",
      "\n",
      "```python\n",
      "from astropy.modeling.models import BlackBody\n",
      "from astropy import units as u\n",
      "from matplotlib import pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "nu = np.geomspace(0.1, 10) * u.micron\n",
      "bb1 = BlackBody(temperature=3000*u.K, scale=1*u.erg/(u.cm ** 2 * u.s * u.Hz * u.sr))\n",
      "bb2 = BlackBody(temperature=3000*u.K, scale=1*u.J/(u.cm ** 2 * u.s * u.Hz * u.sr))\n",
      "bb3 = BlackBody(temperature=3000*u.K, scale=1e7*u.erg/(u.cm ** 2 * u.s * u.Hz * u.sr))\n",
      "\n",
      "fig, ax = plt.subplots()\n",
      "ax.set_xscale('log')\n",
      "ax.set_yscale('log')\n",
      "ax.plot(nu.value, bb1(nu).to_value(u.erg/(u.cm ** 2 * u.s * u.Hz * u.sr)), lw=4, label='bb1')\n",
      "ax.plot(nu.value, bb2(nu).to_value(u.erg/(u.cm ** 2 * u.s * u.Hz * u.sr)), label='bb2')\n",
      "ax.plot(nu.value, bb3(nu).to_value(u.erg/(u.cm ** 2 * u.s * u.Hz * u.sr)), label='bb3')\n",
      "ax.legend()\n",
      "fig.savefig('test.png')\n",
      "```\n",
      "\n",
      "![test](https://user-images.githubusercontent.com/728407/115497738-3e2ef600-a23a-11eb-93b0-c9e358afd986.png)\n",
      "\n",
      "This is great testing of the code.  Thanks!\n",
      "\n",
      "I think I was the one that added this capability.  I don't have time at this point to investigate this issue in detail.  I can look at in the near(ish) future.  If someone else is motivated and has time to investigate and solve, I'm happy to cheer from the sidelines.\n",
      "In pseudocode, here's what the code does with `scale`:\n",
      "\n",
      "* If `scale` has no units, it simply multiplies a standard blackbody.\n",
      "* If `scale` has units that are compatible with flux density, it splits off the value and unit. The value multiplies the standard blackbody, and the output is converted to the given unit.\n",
      "\n",
      "So in both cases, the actual _units_ of the `scale` parameter are ignored. Only the _value_ of the `scale` parameter matters.\n",
      "\n",
      "As nice as the spectral equivalencies are, I think it was a mistake to support a dimensionful `scale` parameter. Clearly that case is completely broken. Can we simply remove that functionality?\n",
      "Beginning to think that the scale keyword should go away (in time, deprecated first of course) and docs updated to clearly show how to convert between units (flam to fnu for example) and remove sterradians.  Astropy does have great units support and the scale functionality can all be accomplished with such.  Not 100% sure yet, looking forward to seeing what others think.\n",
      "\n",
      "The blackbody function would return in default units and scale (fnu seems like the best choice, but kinda arbitrary in the end).\n",
      "\n",
      "If my memory is correct, the scale keyword was partially introduced to be able to reproduce the previous behavior of two backbody functions that were deprecated and have now been removed from astropy.\n",
      "No, I think @astrofrog introduced scale for fitting. The functional, uh, functions that we have removed did not have scaling.\n",
      "FWIW, I still have the old stuff over at https://github.com/spacetelescope/synphot_refactor/blob/master/synphot/blackbody.py . I never got around to using the new models over there. ðŸ˜¬ \n",
      "In trying to handle support for flux units outside of the `BlackBody` model, I ran into a few issues that I'll try to summarize with an example below.\n",
      "\n",
      "```\n",
      "from astropy.modeling import models\n",
      "import astropy.units as u\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "FLAM = u.erg / (u.cm ** 2 * u.s * u.AA)\n",
      "SLAM = u.erg / (u.cm ** 2 * u.s * u.AA * u.sr)\n",
      "\n",
      "wavelengths = np.linspace(2000, 50000, 10001)*u.AA\n",
      "```\n",
      "\n",
      "Using `Scale` to handle the unit conversion fails in the forward model because the `Scale` model will not accept wavelength units as input (it seems `factor` **must** be provided in the same units as the input x-array, but we need output of `sr` for the units to cooperate).\n",
      "\n",
      "```\n",
      "m = models.BlackBody(temperature=5678*u.K, scale=1.0*SLAM) * models.Scale(factor=1.0*u.sr)\n",
      "    \n",
      "fluxes = m(wavelengths)\n",
      "```\n",
      "\n",
      "which gives the error: `Scale: Units of input 'x', Angstrom (length), could not be converted to required input units of sr (solid angle)`.\n",
      "\n",
      "Using `Linear1D` with a slope of 0 and an intercept as the scaling factor (with appropriate units to convert from wavelength to `sr`) does work for the forward model, and yields correct units from the `Compound` model, but fails within fitting when calling `without_units_for_data`:\n",
      "\n",
      "```\n",
      "m = models.BlackBody(temperature=5678*u.K, scale=1.0*SLAM) * models.Linear1D(slope=0.0*u.sr/u.AA, intercept=1.0*u.sr)\n",
      "\n",
      "fluxes = m(wavelengths)\n",
      "m.without_units_for_data(x=wavelengths, y=fluxes)\n",
      "```\n",
      "\n",
      "with the error: `'sr' (solid angle) and 'erg / (Angstrom cm2 s)' (power density/spectral flux density wav) are not convertible`.  It seems to me that this error _might_ be a bug (?), and if it could be fixed, then this approach would technically work for handling the scale and unit conversions externally, but its not exactly obvious or clean from the user-perspective.\n",
      "\n",
      "Is there another approach for handling the conversion externally to the model that works with fitting and `Compound` models?  If not, then either the `without_units_for_data` needs to work for a case like this, or I think `scale` in `BlackBody` might need to be kept and extended to support `FLAM` and `FNU` units as input to allow fluxes as output.\n",
      "While I broadly like the cleanness of @karllark's approach of just saying \"rescale to your hearts desire\", I'm concerned that the ship has essentially sailed.  In particular, I think the following are true:\n",
      "1. Plenty of other models have scale parameters, so users probably took that up conceptually already\n",
      "2. In situations like `specutils` where the blackbody model is used as a tool on already-existing data, it's often useful to carry around the model *with its units*.\n",
      "\n",
      "So to me that argues pretty clearly for \"allow `scale` to have whatever units the user wants. But I see a way to \"have our cake and eat it too\":\n",
      "\n",
      "1. Take the existing blackbody model, remove the `scale`, and call it `UnscaledBlackbodyModel` or something\n",
      "2. Make a new `BlackbodyModel` which is a compound model using `Scale` (with `scale` as the keyword), assuming @kecnry's report that it failed can be fixed (since it sure seems like as a bug).\n",
      "\n",
      "That way we can let people move in the direction @karllark suggested if it seems like people actually like it by telling them to use `UnscaledBlackbodyModel`, but fixing the problem with `Scale` at the same time.  \n",
      "\n",
      "(Plan B, at least if we want something fixed for Astropy 5.0, is to just fix `scale` and have the above be a longer-term plan for maybe 5.1)\n",
      "If someone else wants to do Plan B for ver5.0 as described by @eteq, that's fine with me.  I won't have time before Friday to do such.\n",
      "I think that all of these proposed solutions fail to address the problem that scale units of FLAM or FNU cannot be handled unambiguously, because the reference frequency or wavelength is unspecified.\n",
      "I feel the way forward on this topic is to generate a list of use cases for the use of the scale keyword and then we can figure out how to modify the current code.  These use cases can be coded up into tests.  I have to admit I'm getting a little lost in knowing what all the uses of scale.\n",
      "And if all the use cases are compatible with each other.\n",
      "@lpsinger - agreed.  The `bolometric_flux` method and adding support for flux units to `evaluate` are definitely related, but have slightly different considerations that make this quite difficult.  Sorry if the latter goal somewhat hijacked this issue - but I do think the solution needs to account for both (as well as the unitless \"bug\" in your original post).\n",
      "\n",
      "@karllark - also agreed.  After looking into this in more detail, I think `scale` really has 2 (and perhaps eventually 3) different purposes: a _unitless_ scale to the blackbody equation, determining the output units of `evaluate` and whether it should be wrt wavelength or frequency, and possibly would also be responsible for providing `sterradians` to convert to flux units.  Separating this functionality into three separate arguments might be the simplest to implement and perhaps the clearest and might resolve the `bolometric_flux` concern, but also is clunky for the user and might be a little difficult for backwards compatibility.  Keeping it as one argument is definitely convenient, but confusing and raises issues with ambiguity in `bolometric_flux` mentioned above.\n",
      "@kecnry, I'm concerned that overloading the scale to handle either a unitless value or a value with units of steradians is a footgun, because depending on the units you pass, it may or may not add a factor of pi. This is a footgun because people often think of steradians as being dimensionless.\n",
      "@lpsinger (and others) - how would you feel about splitting the parameters then?  \n",
      "* `scale`: **must** be unitless (or convertible to true unitless), perhaps with backwards compatibility support for SLAM and SNU units that get stripped and interpreted as `output_units`.  I think this can then be used in both `evaluate` and `bolometric_flux`.\n",
      "* `solid_angle` (or similar name): which is only required when wanting the `evaluate` method to output in flux units.  If provided, you must also set a compatible unit for `output_units`.\n",
      "* `output_units` (or similar name): choose whether `evaluate` will output SNU (default as it is now), SLAM, FNU, or FLAM units (with compatibility checks for the other arguments: you can't set this to SLAM or SNU and pass `solid_angle`, for example).\n",
      "\n",
      "The downside here is that in the flux case, fitting both `scale` and `solid_angle` will be entirely degenerate, so one of the two will likely need to be held fixed.  In some use-cases where you don't care about how much of the scale belongs to which units, it might be convenient to just leave one fixed at unity and let the other absorb the full scale factor.  But the upside is that I _think_ this approach might get around the ambiguity cases you brought up?\n",
      "A delta on @kecnry's suggestion to make it a bit less confusing to the user (maybe?) would be to have *3* classes, one that's just `BaseBlackbodyModel` with only the temperature (and no units), a `BlackbodyModel` that's what @kecnry suggeted just above, and a  `FluxButNotDensityReallyIMeanItBlackbodyModel` (ok, maybe a different name is needed there) which has the originally posed `scale` but not `solid_angle`.\n",
      "\n",
      "My motivation here is that I rarely actually want to think about solid angle at all if I can avoid it, but sometimes I have to.\n",
      "@eteq - I would be for that, but then `FluxButNotDensityReallyIMeanItBlackbodyModel` would likely have to raise an error if calling `bolometric_flux` or possibly could estimate through integration (over wavelength or frequency) instead.\n",
      "Yeah, I'm cool with that, as long as the exception message says something like \"not sure why you're seeing this?  Try using BlackbodyModel instead\"\n",
      "If you end up with a few new classes, the user documentation needs some serious explaining, as I feel like this is going against \"There should be one-- and preferably only one --obvious way to do it\" ([PEP 20](https://www.python.org/dev/peps/pep-0020/)) a little...\n",
      "@eteq @pllim - it might be possible to achieve this same use-case (not having to worry about thinking about solid angle if you don't intend to make calls to `bolometric_flux`) in a single class by allowing `solid_angle = None` for the flux case and absorbing the steradians into the scale factor.  That case would then need to raise an informative error for calls to `bolometric_flux` to avoid the ambiguity issue.  The tradeoff I see is more complex argument validation logic and extended documentation in a single class rather than multiple classes for different use-cases.\n",
      "\n",
      "If no one thinks of any major drawbacks/concerns, I will take a stab at that implementation and come up with examples for each of the use-cases discussed so far and we can then reconsider if splitting into separate classes is warranted.\n",
      "\n",
      "Thanks for all the good ideas!\n",
      "Here are some proposed pseudo-code calls that I think could cover all the cases above with a single class including new optional `solid_angle` and `output_units` arguments.  Please let me know if I've missed any cases or if any of these wouldn't act as you'd expect.  \n",
      "\n",
      "As you can see, there are quite a few different scenarios, so this is likely to be a documentation and testing challenge - but I'm guessing any approach will have that same problem.  Ultimately though it boils down to attempting to pull the units out of `scale` to avoid the ambiguous issues brought up here, while still allowing support for output and fitting in flux units (by supporting both separating the dimensionless scale from the solid angle to allow calling `bolometric_flux` and also by absorbing them together for the case of fitting a single scale factor and sacrificing the ability to call `bolometric_flux`).\n",
      "\n",
      "\n",
      "**SNU/SLAM units**\n",
      "\n",
      "`BlackBody(temperature, [scale (float or unitless)], output_units=(None, SNU, or SLAM))`\n",
      "* if `output_units` is not provided or `None`, defaults to `SNU` to match current behavior\n",
      "* unitless `scale` converted to unitless_unscaled (should address this *original* bug report)\n",
      "* returns in SNU/SLAM units \n",
      "* `bolometric_flux` uses unitless `scale` directly (matches current behavior)\n",
      "\n",
      "\n",
      "`BlackBody(temperature, scale (SNU or SLAM units))`\n",
      "* for **backwards compatibility** only\n",
      "* `output_units = scale.unit`, `scale = scale.value`\n",
      "* returns in SNU/SLAM units\n",
      "* `bolometric_flux`: we have two options here: (1) interpret this as a unitless `scale` with units being interpreted only for the sake of output units which matches current behavior (2) raise an error that `bolometric_flux` requires unitless `scale` to be passed (see [point 3 in the comment above](https://github.com/astropy/astropy/issues/11547#issuecomment-822667522)).\n",
      "\n",
      "\n",
      "`BlackBody(temperature, scale (with other units), output_units=(None, SNU, or SLAM))`\n",
      "* **ERROR**: `scale` cannot have units if `output_units` are SNU or SLAM (or non-SNU/SLAM units if `output_units` not provided or None)\n",
      "\n",
      "**FNU/FLAM units**\n",
      "\n",
      "`BlackBody(temperature, scale (float or unitless), solid_angle (u.sr), output_units=(FNU or FLAM))`\n",
      "* unitless `scale` converted to unitless_unscaled\n",
      "* returns in FNU/FLAM\n",
      "* `bolometric_flux` uses unitless `scale` directly (since separated from `solid_angle`)\n",
      "* fitting: either raise an error if both `scale` and `solid_angle` are left unfixed or just let it be degenerate?\n",
      "\n",
      "`BlackBody(temperature, scale (sr units), output_units=(FNU or FLAM))`\n",
      "* `scale = scale.value`, `solid_angle = 1.0*u.sr` and **automatically set to be kept fixed** during fitting\n",
      "* returns in FNU/FLAM\n",
      "* `bolometric_flux` => ERROR: must provide separate `scale` and `solid_angle` to call `bolometric_flux` (i.e. the previous case)\n",
      "\n",
      "`BlackBody(temperature, scale (FNU or FLAM units))`\n",
      "* to match **backwards compatibility** case for SNU/SLAM\n",
      "* `output_units = scale.unit`, `scale = scale.value`, `solid_angle = 1.0*u.sr` and **automatically set to be kept fixed** during fitting\n",
      "* returns in FNU/FLAM units\n",
      "* `bolometric_flux` => ERROR: same as above, must provide separate `scale` and `solid_angle`.\n",
      "\n",
      "`BlackBody(temperature, scale (float, unitless, or non sr units), output_units=(FNU or FLAM))`\n",
      "* **ERROR**: FNU/FLAM requires scale to have FNU/FLAM/sr units OR unitless with solid_angle provided (any of the cases above)\n",
      "Upon further reflection, I think that we are twisting ourselves into a knot by treating the black body as a special case when it comes to this pesky factor of pi. It's not. The factor of pi comes up any time that you need to convert from specific intensity (S_nu a.k.a. B_nu [erg cm^-2 s^-1 Hz^-1 sr^-1]) to flux density (F_nu [erg cm^-2 s^-1 Hz^-1]) assuming that your emitting surface element radiates isotropically. It's just the integral of cos(theta) from theta=0 to pi/2.\n",
      "\n",
      "BlackBody only looks like a special case among the astropy models because there are no other physical radiation models. If we declared a constant specific intensity source model class, then we would be having the same argument about whether we need to have a dual flux density class with an added factor of pi.\n",
      "\n",
      "What we commonly call Planck's law is B_nu. In order to avoid confusing users who are expecting the class to use the textbook definition, the Astropy model should _not_ insert the factor of pi.\n",
      "\n",
      "Instead, I propose that we go back to for `astropy.modeling.models.BlackBody`:\n",
      "\n",
      "1. `scale` may have units of dimensionless_unscaled or solid angle, and in either case simply multiplies the output, or\n",
      "2. has no scale parameter.\n",
      "\n",
      "In both cases, support for scale in FNU/FLAM/SNU/SLAM is deprecated because it cannot be implemented correctly and unambiguously.\n",
      "\n",
      "And in both cases, synphot keeps its own BlackBody1D class (perhaps renamed to BlackBodyFlux1D to mirror ConstFlux1D) and it _does_ have the factor of pi added.\n",
      "BTW, I found this to be a nice refresher: https://www.cv.nrao.edu/~sransom/web/Ch2.html\n",
      "> synphot keeps its own BlackBody1D class (perhaps renamed to BlackBodyFlux1D to mirror ConstFlux1D)\n",
      "\n",
      "`synphot` never used the new blackbody stuff here, so I think it can be safely left out of the changes here. If you feel strongly about its model names, feel free to open issue at https://github.com/spacetelescope/synphot_refactor/issues but I don't think it will affect anything at `astropy` or vice versa. ðŸ˜… \n",
      "@lpsinger - good points. I agree that this situation isn't fundamentally unique to BlackBody, and on further thought along those lines, can't think of any practical reason not to abstract away the `solid_angle` entirely from my use-cases above (as it should probably always either be N/A or pi - allowing it to possibly be fitted or set incorrectly just asks for problems).  I have gone back and forth with myself about your point for *not* adding support for including the pi automatically, but as long as the default behavior remains the \"pure\" B_nu form, I think there are significant practical advantages for supporting more flexibility.  The more this conversation continues, the more convinced I am that `scale` is indeed useful, but that we should move towards forcing it to be unitless to avoid a lot of these confusing scenarios.  I'm worried that allowing `scale` to have steradians as units will cause more confusion (although I appreciate the simplicity of just multiplying the result).\n",
      "\n",
      "So... my (current) vote would be to still implement a separate `output_units` argument to make sure any change in units (and/or inclusion of pi) is explicitly clear and to take over the role of differentiating between specific intensity and flux density (by eventually requiring `scale` to be unitless and always handling the pi internally if requesting in flux units).\n",
      "\n",
      "Assuming we can't remove support for units in `scale` this release without warning, that leaves us with the following:\n",
      "\n",
      "* `BlackBody(temperature, [scale (float or unitless)], output_units=(None, SNU, or SLAM))`\n",
      "* temporary support for `BlackBody(temperature, scale (SNU or SLAM units))`: this is the current supported syntax that we want to deprecate. In the meantime, we would split the `scale` quantity into `scale` (unitless) and `output_units`.  I think this still might be a bit confusing for the `bolometric_flux` case, so we may want to raise an error/warning there?\n",
      "* `BlackBody(temperature, [scale (float or unitless)], output_units=(FNU or FLAM))`: since scale is unitless, it is assumed *not* to include the pi, the returned value is multiplied by `scale*pi` internally and with requested units.\n",
      "* temporary support for `BlackBody(temperature, scale (FNU, FLAM))`: here `scale` includes units of solid angle, so internally we would set `scale = scale.value/pi` and then use the above treatment to multiply by `scale*pi`.  Note that this does mean the these last two cases behave a little differently for passing the same \"number\" to `scale`, as without units it assumes to not include the pi, but will assume to include the pi if passed as a quantity. Definitely not ideal - I suppose we don't need to add support for this case since it wasn't supported in the past.  But if we do, we may again want to raise an error/warning when calling `bolometric_flux`?\n",
      "\n",
      "If we don't like the `output_units` argument, this could be done instead with `BlackBody` vs `BlackBodyFlux` model (similar to @eteq's suggestion earlier), still deprecate passing units to scale as described above for both classes, and leave any unit conversion between *NU and *LAM to the user.  Separate classes may be slightly cleaner looking and help separate the documentation, while a single class with the `output_units` argument provides a little more convenience functionality.\n",
      "I think we should not include the factor of pi at all in the astropy model because it assumes not only that one is integrating over a solid angle, but that the temperature is uniform over the body. In general, that does not have to be the case, does it?\n",
      "\n",
      "Would we ruffle too many feathers if we deprecated `scale` altogether?\n",
      "> Would we ruffle too many feathers\n",
      "\n",
      "Can't be worse than the episode when we deprecated `clobber` in `io.fits`... ðŸ˜… \n",
      "No, not in general.  But so long as we only support a single temperature, I think it's reasonable that that would assume uniform temperature. \n",
      "\n",
      "I think getting rid of `scale` entirely was @karllark's original suggestion, but then all of this logic is left to be done externally (likely by the user).  My attempts to do so with the existing `Scale` or `Linear1D` models, [showed complications](https://github.com/astropy/astropy/issues/11547#issuecomment-949734738).  Perhaps I was missing something there and there's a better way... or maybe we need to work on fixing underlying bugs or lack of flexibility in `Compound` models instead.  I also agree with @eteq's [arguments that users would expect a scale](https://github.com/astropy/astropy/issues/11547#issuecomment-951154117) and that it might indeed ruffle some feathers.\n",
      "> No, not in general. But so long as we only support a single temperature, I think it's reasonable that that would assume uniform temperature.\n",
      "\n",
      "It may be fair to assume a uniform temperature, but the factor of pi is also kind of assuming that the emitting surface is a sphere, isn't it?\n",
      "\n",
      "> I think getting rid of `scale` entirely was @karllark's original suggestion, but then all of this logic is left to be done externally (likely by the user). My attempts to do so with the existing `Scale` or `Linear1D` models, [showed complications](https://github.com/astropy/astropy/issues/11547#issuecomment-949734738). Perhaps I was missing something there and there's a better way... or maybe we need to work on fixing underlying bugs or lack of flexibility in `Compound` models instead. I also agree with @eteq's [arguments that users would expect a scale](https://github.com/astropy/astropy/issues/11547#issuecomment-951154117) and that it might indeed ruffle some feathers.\n",
      "\n",
      "I see. In that case, it seems that we are converging toward retaining the `scale` attribute but deprecating any but dimensionless units for it. Is that an accurate statement? If so, then I can whip up a PR.\n",
      "Yes, most likely a sphere, or at least anything where the solid angle is pi.  But I agree that adding the generality for any solid angle will probably never be used and just adds unnecessary complication.\n",
      "\n",
      "I think that's the best approach for now (deprecating unit support in `scale` but supporting flux units) and then if in the future we want to completely remove `scale`, that is an option as long as external scaling can pick up the slack.  I already started on testing some implementations, so am happy to put together the PR (and will tag you so you can look at it and comment before any decision is made).\n",
      "> I think that's the best approach for now (deprecating unit support in `scale` but supporting flux units) and then if in the future we want to completely remove `scale`, that is an option as long as external scaling can pick up the slack. I already started on testing some implementations, so am happy to put together the PR (and will tag you so you can look at it and comment before any decision is made).\n",
      "\n",
      "Go for it.\n",
      "\n",
      "\n",
      "\n",
      "END OF HINT\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "END OF HINT\n",
      "\n",
      "\n",
      "\n",
      "Hmm. Maybe the logic here needs fixing:\n",
      "\n",
      "https://github.com/astropy/astropy/blob/bcde23429a076859af856d941282f3df917b8dd4/astropy/table/groups.py#L351-L360\n",
      "Mostly finished with a fix for this which makes it possible to aggregate tables that have mixin columns. In cases where the aggregation makes sense (e.g. with Quantity) it will just work. In other cases a warning only.\n",
      "\n",
      "\n",
      "\n",
      "END OF HINT\n",
      "\n",
      "\n",
      "\n",
      "I hope you don't mind me tagging you @taldcroft as it was your commit, maybe you can help me figure out if this is a bug or an evolution in `astropy.TimeSeries` that requires an alternative file format? I was pretty happy using ecsv formatted files to save complex data as they have been pretty stable, easy to visually inspect, and read in/out of scripts with astropy. \n",
      "\n",
      "\n",
      "[example_file.dat.txt](https://github.com/astropy/astropy/files/8043511/example_file.dat.txt)\n",
      "(Also I had to add a .txt to the filename to allow github to put it up.)\n",
      "@emirkmo - sorry, it was probably a mistake to make the reader be strict like that and raise an exception. Although that file is technically non-compliant with the ECSV spec, the reader should instead issue a warning but still carry on if possible (being liberal on input). I'll put in a PR to fix that.\n",
      "\n",
      "The separate issue is that the `Time` object has a format of `datetime64` which leads to that unexpected numpy dtype in the output. I'm not immediately sure of what the right behavior for writing ECSV should be there. Maybe actually just `datetime64` as an allowed type, but that opens a small can of worms itself. Any thoughts @mhvk?\n",
      "\n",
      "One curiosity @emirko is how you ended up with the timeseries object `time_bin_start` column having that `datetime64` format (`ts['time_bin_start'].format`). In my playing around it normally has `isot` format, which would not have led to this problem.\n",
      "I would be happy to contribute this PR @taldcroft, as I have been working on it on a local copy anyway, and am keen to get it working. I currently monkey patched ecsv in my code to not raise, and it seems to work. If you let me know what the warning should say, I can make a first attempt. `UserWarning` of some sort? \n",
      "\n",
      "The `datetime64` comes through a chain:\n",
      "\n",
      " - Data is read into `pandas` with a `datetime64` index.\n",
      " - `TimeSeries` object is created using `.from_pandas`.\n",
      " - `aggregate_downsample` is used to turn this into a `BinnedTimeSeries`\n",
      " - `BinnedTimeSeries` object is written to an .ecsv file using its internal method.\n",
      "\n",
      "Here is the raw code, although some of what you see may be illegible due to variable names. I didn't have easy access to the original raw data anymore, hence why I got stuck in trying to read it from the binned light curve. \n",
      "```\n",
      "perday = 12\n",
      "Tess['datetime'] = pd.to_datetime(Tess.JD, unit='D', origin='julian')\n",
      "ts = TimeSeries.from_pandas(Tess.set_index('datetime'))\n",
      "tsb = aggregate_downsample(ts, time_bin_size=(1.0/perday)*u.day, \n",
      "                           time_bin_start=Time(beg.to_datetime64()), n_bins=nbin)\n",
      "tsb.write('../Photometry/Tess_binned.ecsv', format='ascii.ecsv', overwrite=True)\n",
      "```\n",
      "My PR above at least works for reading in the example file and my original file. Also passes my local tests on io module. \n",
      "Ouch, that is painful! Apart from changing the error to a warning (good idea!), I guess the writing somehow should change the data type from `datetime64` to `string`. Given that the format is stored as `datetime64`, I think this would still round-trip fine. I guess it would mean overwriting `_represent_as_dict` in `TimeInfo`.\n",
      "> I guess it would mean overwriting _represent_as_dict in TimeInfo\n",
      "\n",
      "That's where I got to, we need to be a little more careful about serializing `Time`. In some sense I'd like to just use `jd1_jd2` always for Time in ECSV (think of this as lossless serialization), but that change might not go down well.\n",
      "Yes, what to pick is tricky: `jd1_jd2` is lossless, but much less readable.\n",
      "As a user, I would expect the serializer picked to maintain the current time format in some way, or at least have a general mapping from all available  formats to the most nearby easily serializable ones if some of them are hard to work with. (Days as ISOT string, etc.)\n",
      "\n",
      "ECSV seems designed to be human readable so I would find it strange if the format was majorly changed, although now I see that all other ways of saving the data use jd1_jd2. I assume a separate PR is needed for changing this.\n",
      "\n",
      "Indeed, the other formats use `jd1_jd2`, but they are less explicitly meant to be human-readable.  I think this particular case of numpy datetime should not be too hard to fix, without actually changing how the file looks.\n",
      "Agreed to keep the ECSV serialization as the `value` of the Time object.\n",
      "\n",
      "\n",
      "\n",
      "END OF HINT\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print first hints text\n",
    "first_hints = test_df[\"hints_text\"].loc[0:5]\n",
    "for hint in first_hints:\n",
    "    print(hint)\n",
    "    print(\"\\n\\n\\nEND OF HINT\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     3832210580d516365ddae1a62071001faf94d416\n",
      "1     b6769c18c0881b6d290e543e9334c25043018b3f\n",
      "2     43ce7895bb5b61d4fab2f9cc7d07016cf105f18e\n",
      "3     3a0cd2d8cd7b459cdc1e1b97a14f3040ccc1fffc\n",
      "4     43ee5806e9c6f7d58c12c1cb9287b3c61abe489d\n",
      "5     3a0cd2d8cd7b459cdc1e1b97a14f3040ccc1fffc\n",
      "6     b49ad06b4de9577648a55d499d914e08baeef2c6\n",
      "7     691ceab8aea8f7c37ee89b1b806801239bb2dc69\n",
      "8     d16bfe05a744909de4b27f5875fe0d4ed41ce607\n",
      "9     d21dc232d8626b3aff24784628a6e85d177784ae\n",
      "10    d707b792d3ca45518a53b4a395c81ee86bd7b451\n",
      "11    298ccb478e6bf092953bca67a3d29dc6c35f6752\n",
      "12    2288ecd4e9c4d3722d72b7f4a6555a34f4f04fc7\n",
      "13    43ee5806e9c6f7d58c12c1cb9287b3c61abe489d\n",
      "14    c660b079b6472920662ca4a0c731751a0342448c\n",
      "15    3a0cd2d8cd7b459cdc1e1b97a14f3040ccc1fffc\n",
      "16    b185ca184f8dd574531dcc21e797f00537fefa6a\n",
      "17    78c4ac119a182eee14cb3761e0dc9ea0e59b291f\n",
      "18    11b3214f18b74aea5e3f8349e50ae1b09c39d30e\n",
      "19    6ed769d58d89380ebaa1ef52b300691eefda8928\n",
      "20    b3fa7702635b260b008d391705c521fca7283761\n",
      "21    1e75f298aef2540240c63b4075d06851d55fc19a\n",
      "22    6500928dc0e57be8f06d1162eacc3ba5e2eff692\n",
      "23    16743c6faf5cb8433bf9f7702ae70d002a96caaf\n",
      "24    7539d76ceae146f930d4473107d9940d2fc0b74f\n",
      "25    4bd88be61fdf4185b9c198f7e689a40041e392ee\n",
      "26    19cc80471739bcb67b7e8099246b391c355023ee\n",
      "27    d441bfdbb8e6dc57a52d8c1b117cadd030f0657a\n",
      "28    0f3e4a6549bc8bb3276184a021ecdd3482eb5d13\n",
      "29    2b8631e7d64bfc16c70f5c51cda97964d8dd1ae0\n",
      "30    c40b75720a64186b57ad1de94ad7f21fa7728880\n",
      "31    986123f73ce94d4511f453dbdd4470c72f47402a\n",
      "32    0df94ff7097961e92fd7812036a24b145bc13ca8\n",
      "33    c00626462ee48a483791d92197582e7d1366c9e0\n",
      "34    7ea140de86b788b44f64ea5eeacfbd78ffd85b69\n",
      "35    a30301e5535be2f558cb948da6b3475df4e36a98\n",
      "36    9fd247339e51441460b43368d415fced327c97a2\n",
      "37    0446f168dc6e34996482394f00770b52756b8f9c\n",
      "38    192be538570db75f1f3bf5abe0c7631750e6addc\n",
      "39    a6c712375ed38d422812e013566a34f928677acd\n",
      "40    3b448815e21b117d34fe63007b8ef63ee084fefb\n",
      "41    5aa2d0beca53988e054d496c6dcfa2199a405fb8\n",
      "42    5250b2442501e6c671c6b380536f1edb352602d1\n",
      "43    6720a70d8dd9108317e21e8577caccecdde781f3\n",
      "44    1a4462d72eb03f30dc83a879b1dd57aac8b2c18b\n",
      "45    d083189bbc188807c3d62bd419ea5bbf38cf7d56\n",
      "46    a5917978be39d13cd90b517e1de4e7a539ffaa48\n",
      "47    a5ccc9522ca139df7a7cf4e2e506ffd288e55620\n",
      "48    dd2304672cdf4ea1b6f124f9f22ec5069a13c9f5\n",
      "49    15cc8f20a4f94ab1910bc865f40ec69d02a7c56c\n",
      "50    cdb66059a2feb44ee49021874605ba90801f9986\n",
      "Name: base_commit, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# list the first 50 base_commits\n",
    "base_commits = test_df[\"base_commit\"].loc[0:50]\n",
    "print(base_commits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['astropy/astropy' 'django/django' 'matplotlib/matplotlib'\n",
      " 'mwaskom/seaborn' 'pallets/flask' 'psf/requests' 'pydata/xarray'\n",
      " 'pylint-dev/pylint' 'pytest-dev/pytest' 'scikit-learn/scikit-learn'\n",
      " 'sphinx-doc/sphinx' 'sympy/sympy']\n"
     ]
    }
   ],
   "source": [
    "unique_repos = test_df[\"repo\"].unique()\n",
    "print(unique_repos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
